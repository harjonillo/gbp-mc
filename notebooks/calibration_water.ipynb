{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/yq0x0lnn2ns__6748g658mxm0000gn/T/ipykernel_45089/714872020.py:12: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  mplstyle.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib.style as mplstyle\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "import src.core.gaussian_beam_propagation as gbp\n",
    "from src.core.gaussian_beam_propagation import FocusedGaussianBeam\n",
    "from src.core import intersect\n",
    "\n",
    "mplstyle.use('seaborn')\n",
    "sns.set_style(\"darkgrid\", {'axes.grid' : False})\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(sns.cubehelix_palette(100, start=.5, rot=-.75, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../data/calibration_water\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/calibration_water/\n"
     ]
    }
   ],
   "source": [
    "print (datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename(code, num_photons, num_steps, scat_deg, g, trial, mod=None):\n",
    "    names = [f'ray', f'out', f'med', f'his', f'medprop']\n",
    "    desc = f'N{num_photons}s{num_steps}R{int(scat_deg)}g{int(g*10)}t{trial}'\n",
    "    if mod is not None:\n",
    "        desc += mod\n",
    "    return names[code] + desc + f'.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_id(scattering_degree, g, trials):\n",
    "    subfoldir = '' # f'r{scattering_degree}'\n",
    "    fullpath = os.path.join(datadir, subfoldir)\n",
    "    rays = np.load(os.path.join(fullpath, f'rayR{int(scattering_degree)}g{int(g*10)}t{trial}.npy'))\n",
    "#     rays = np.load('r2' + f'rayR{int(scattering_degree)}g{int(g*10)}t{trial}.npy')\n",
    "    scattered_out = np.load(os.path.join(fullpath, f'outR{int(scattering_degree)}g{int(g*10)}t{trial}.npy'))\n",
    "    scatterer_centers = np.load(os.path.join(fullpath, f'medR{int(scattering_degree)}g{int(g*10)}t{trial}.npy'))\n",
    "    scatter_history = np.load(os.path.join(fullpath, f'hisR{int(scattering_degree)}g{int(g*10)}t{trial}.npy'))\n",
    "    scat_props = np.load(os.path.join(fullpath, f'medpropR{int(scattering_degree)}g{int(g*10)}t{trial}.npy'))\n",
    "    \n",
    "    rays = np.concatenate(rays, axis=1)\n",
    "    scattered_out = np.concatenate(scattered_out.reshape(10, 1000, 100), axis=0)\n",
    "    scatter_history = np.concatenate(scatter_history.reshape(10, 1000, 100), axis=0)\n",
    "    \n",
    "    return rays, scattered_out, scatterer_centers, scatter_history, scat_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_join_trials(code, num_trials, num_photons, num_steps, scattering_degree, g, mod=None):\n",
    "    subfoldir = '' # f'r{scattering_degree}'\n",
    "    fullpath = os.path.join(datadir, subfoldir)\n",
    "    file = filename(code, num_photons, num_steps, scattering_degree, g, trial=0)\n",
    "    t0 = np.load(os.path.join(fullpath, file))\n",
    "    arr = []\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        temp = np.load(os.path.join(fullpath, filename(code, num_photons, num_steps, scattering_degree, g, trial, mod)))\n",
    "#         if code == 0:\n",
    "#             temp = temp.reshape(10, 3, temp.shape[-2], temp.shape[-1]//10)\n",
    "#             temp = np.concatenate(temp, axis=1)\n",
    "#         elif (code == 1) or (code == 3):\n",
    "#             temp = temp.reshape(10, temp.shape[-2], temp.shape[-1]//10)\n",
    "#             temp = np.concatenate(temp, axis=0)\n",
    "        arr.append(temp)\n",
    "#         arr[trial] = np.load(subfoldir + filename(code, scattering_degree, g, trial))\n",
    "        \n",
    "    return np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rays_to_contour(rays, axial_range=20, resolution=201):\n",
    "    num_steps = rays.shape[2]\n",
    "    axial_planes = np.linspace(-axial_range, axial_range, resolution)\n",
    "    intersections_per_plane = [[],[]]\n",
    "    \n",
    "    for p in range(len(axial_planes)):\n",
    "        for step in range(num_steps-1):\n",
    "            # check if rays intersect this plane at all\n",
    "            plane = axial_planes[p]\n",
    "            intersects_plane = (rays[2, :, step+1] > plane) & (rays[2, :, step] < plane)\n",
    "            # calculate points of intersection for this plane\n",
    "            intersections = intersect.ray_xyplane(plane, rays[:, intersects_plane, step], rays[:, intersects_plane, step+1])\n",
    "            intersections_per_plane[0].extend(intersections[0])\n",
    "            intersections_per_plane[1].extend(intersections[2])\n",
    "            \n",
    "    return intersections_per_plane, axial_planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linfoot(signal_expt, signal_theo):\n",
    "    '''\n",
    "    C: relative structural content\n",
    "    F: fidelity\n",
    "    Q: correlation quality\n",
    "    '''\n",
    "    # normalize\n",
    "    sig_expt_sum = np.sum(signal_expt)\n",
    "    sig_theo_sum = np.sum(signal_theo)\n",
    "    if sig_expt_sum != 0:\n",
    "        signal_expt /= sig_expt_sum\n",
    "    if sig_theo_sum != 0:\n",
    "        signal_theo /= sig_theo_sum\n",
    "    C = np.sum(signal_expt**2) / np.sum(signal_theo**2)\n",
    "    F = 1 - np.sum((signal_expt - signal_theo)**2)/np.sum(signal_theo**2)\n",
    "    Q = np.sum(signal_expt*signal_theo) / np.sum(signal_theo**2)\n",
    "\n",
    "    return C, F, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots2(X, Z, intensity, alpha):\n",
    "    extent = (-15, 15, -15//2, 15//2)\n",
    "    print(extent)\n",
    "    # X for x axis, Z for y axis\n",
    "    fig = pl.figure()\n",
    "\n",
    "    ax1 = pl.subplot2grid((3, 5), (0, 0), colspan=4)\n",
    "    ax2 = pl.subplot2grid((3, 5), (1, 0), colspan=4, rowspan=2)\n",
    "    ax3 = pl.subplot2grid((3, 5), (1, 4), rowspan=2)\n",
    "\n",
    "    ax1.plot(X[0], intensity[intensity.shape[0]//2, :])\n",
    "    ax1.set_xlim(extent[0], extent[1])\n",
    "    ax2.contour(intensity, levels=np.logspace(-4,1, 20), cmap=pl.cm.gray, linewidths=0.5, extent=extent)\n",
    "#     ax2.contour(intensity, levels=[np.amax(intensity)/np.e**2], cmap=pl.cm.gray, linewidths=1.0, extent=extent)\n",
    "    ax2.imshow(intensity, cmap=cmap, extent=extent)\n",
    "    ax3.plot(intensity[:, intensity.shape[1]//2], Z[:, 0])\n",
    "    ax3.set_ylim(extent[2], extent[3])\n",
    "    \n",
    "    pl.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theo_dists(beam):\n",
    "    u = np.linspace(-30, 30, 200, dtype=np.float64)\n",
    "    v = np.linspace(-15, 15, 100, dtype=np.float64)\n",
    "    \n",
    "    V, U, field = beam.debye_approx_field(v, u)\n",
    "    intensity = np.array(np.abs(field)**2, dtype=np.float64)\n",
    "    intensity = intensity / np.amax(intensity)\n",
    "    \n",
    "    axial_profile = intensity[intensity.shape[0]//2, :]\n",
    "    transverse_profile = intensity[:, intensity.shape[1]//2]\n",
    "    \n",
    "    return u, v, intensity, transverse_profile, axial_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/calibration_water/rayN30000s3.9810717055349853e-19R0g0t0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39melse\u001b[39;00m: \n\u001b[1;32m     14\u001b[0m         g \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m\n\u001b[0;32m---> 15\u001b[0m     rays \u001b[39m=\u001b[39m load_and_join_trials(\u001b[39m0\u001b[39;49m, num_trials\u001b[39m=\u001b[39;49mnum_trials, num_steps\u001b[39m=\u001b[39;49mstep_param, num_photons\u001b[39m=\u001b[39;49mnum_photons,\n\u001b[1;32m     16\u001b[0m                                 scattering_degree\u001b[39m=\u001b[39;49mscat_degree, g\u001b[39m=\u001b[39;49mg)\n\u001b[1;32m     17\u001b[0m     R\u001b[39m.\u001b[39mappend(rays)\n\u001b[1;32m     19\u001b[0m transverse_intensities \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m, in \u001b[0;36mload_and_join_trials\u001b[0;34m(code, num_trials, num_photons, num_steps, scattering_degree, g, mod)\u001b[0m\n\u001b[1;32m      3\u001b[0m fullpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(datadir, subfoldir)\n\u001b[1;32m      4\u001b[0m file \u001b[39m=\u001b[39m filename(code, num_photons, num_steps, scattering_degree, g, trial\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m t0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(fullpath, file))\n\u001b[1;32m      6\u001b[0m arr \u001b[39m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m trial \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_trials):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/gbpmc-env/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/calibration_water/rayN30000s3.9810717055349853e-19R0g0t0.npy'"
     ]
    }
   ],
   "source": [
    "R = []\n",
    "num_trials = 5\n",
    "g = 0.2\n",
    "num_photons = 30000\n",
    "num_steps = 100\n",
    "step_param_arr = np.logspace(-18.4, -18, 10)\n",
    "# step_param_arr = [8.2e-18]\n",
    "scat_degree = 0\n",
    "for s in range(len(step_param_arr)):\n",
    "    step_param = step_param_arr[s]\n",
    "    if scat_degree == 0:\n",
    "        g = 0\n",
    "    else: \n",
    "        g = 0.2\n",
    "    rays = load_and_join_trials(0, num_trials=num_trials, num_steps=step_param, num_photons=num_photons,\n",
    "                                scattering_degree=scat_degree, g=g)\n",
    "    R.append(rays)\n",
    "    \n",
    "transverse_intensities = []\n",
    "axial_intensities = []\n",
    "axial_intensities_std = []\n",
    "hists = []\n",
    "transverse_edges = []\n",
    "axial_edges = []\n",
    "\n",
    "h_ave = []\n",
    "h_std = []\n",
    "\n",
    "for s in range(len(R)): \n",
    "    print(s)\n",
    "    rays = R[s]\n",
    "    for trial in range(5):\n",
    "#         print(rays[trial].shape)\n",
    "        intersections_per_plane, axial_planes = rays_to_contour(rays[trial])\n",
    "        intersections_per_plane = np.array(intersections_per_plane)\n",
    "#         print(intersections_per_plane.shape)\n",
    "        h, xedges, yedges = np.histogram2d(intersections_per_plane[0], intersections_per_plane[1], bins=[axial_planes, axial_planes])\n",
    "        hists.append(h)\n",
    "    histsarr = np.array(hists)\n",
    "    h_ave.append(np.average(histsarr, axis=0))\n",
    "    h_std.append(np.std(histsarr, axis=0))\n",
    "    del histsarr\n",
    "\n",
    "#     print(h_ave[scat_degree].shape)\n",
    "    transverse_intensities.append(h_ave[s][:, h_ave[s].shape[1]//2])\n",
    "    axial_intensities.append(h_ave[s][h_ave[s].shape[1]//2, :])\n",
    "    axial_intensities_std.append(h_std[s][h_std[s].shape[1]//2, :])\n",
    "    hists.append(h)\n",
    "    axial_edges.append(xedges)\n",
    "    transverse_edges.append(yedges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('transverse_edges.npy', np.array(transverse_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/calibration_water/h_ave.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m axial_intensities \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdatadir\u001b[39m}\u001b[39;00m\u001b[39m/axial_intensities.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m axial_intensities_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdatadir\u001b[39m}\u001b[39;00m\u001b[39m/axial_intensities_std.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m h_ave \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mdatadir\u001b[39m}\u001b[39;49;00m\u001b[39m/h_ave.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m h_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdatadir\u001b[39m}\u001b[39;00m\u001b[39m/h_std.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m axial_edges \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdatadir\u001b[39m}\u001b[39;00m\u001b[39m/axial_edges.npy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/gbpmc-env/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/calibration_water/h_ave.npy'"
     ]
    }
   ],
   "source": [
    "transverse_intensities = np.load(f'{datadir}/transverse_intensities.npy')\n",
    "axial_intensities = np.load(f'{datadir}/axial_intensities.npy')\n",
    "axial_intensities_std = np.load(f'{datadir}/axial_intensities_std.npy')\n",
    "h_ave = np.load(f'{datadir}/h_ave.npy')\n",
    "h_std = np.load(f'{datadir}/h_std.npy')\n",
    "axial_edges = np.load(f'{datadir}/axial_edges.npy')\n",
    "transverse_edges = np.load(f'{datadir}/transverse_edges.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_nocurve = []\n",
    "num_trials = 5\n",
    "g = 0.2\n",
    "num_photons = 30000\n",
    "num_steps = 100\n",
    "# step_param_arr = np.logspace(-18.5, -17.5, 10)\n",
    "# step_param_arr = [8.2e-18]\n",
    "scat_degree = 0\n",
    "for s in range(len(step_param_arr)):\n",
    "    step_param = step_param_arr[s]\n",
    "    if scat_degree == 0:\n",
    "        g = 0\n",
    "    else: \n",
    "        g = 0.2\n",
    "    rays = load_and_join_trials(0, num_trials, num_photons, step_param_arr[0], scat_degree, g, mod=f'-nocurve')\n",
    "    R_nocurve.append(rays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam = FocusedGaussianBeam(NA=0.4, n=1.33, z_f=0, trunc_coeff=4)\n",
    "x = (transverse_edges[scat_degree][1:] + transverse_edges[scat_degree][1:])/2\n",
    "z = (axial_edges[scat_degree][1:] + axial_edges[scat_degree][:-1])/2\n",
    "\n",
    "u, v, intensity, transverse_profile, axial_profile = get_theo_dists(beam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcbeam = gbp.FocusedGaussianBeamMC(num_photons=1.0E3, num_iterations=100, curvature_correction=False, axial_resolution=200, beam_dist='gaussian', num_steps=100, NA=0.4, n=1.33, z_f=0, trunc_coeff=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transverse_intensities_nc = []\n",
    "axial_intensities_nc = []\n",
    "axial_intensities_std_nc = []\n",
    "hists_nc = []\n",
    "transverse_edges_nc = []\n",
    "axial_edges_nc = []\n",
    "\n",
    "h_ave_nc = []\n",
    "h_std_nc = []\n",
    "\n",
    "for s in range(len(R_nocurve)): \n",
    "    rays = R_nocurve[s]\n",
    "    for trial in range(5):\n",
    "        h, trans_edges, ax_edges = mcbeam.rays_to_intensity(rays[trial],\n",
    "                                                            trans_img_range=[transverse_edges[0][0], transverse_edges[0][-1]],\n",
    "                                                            axial_img_range=[axial_edges[0][0], axial_edges[0][-1]],\n",
    "                                                            axial_resolution=201)\n",
    "        hists_nc.append(h)\n",
    "    histsarr = np.array(hists_nc)\n",
    "    h_ave_nc.append(np.average(histsarr, axis=0))\n",
    "    h_std_nc.append(np.std(histsarr, axis=0))\n",
    "    del histsarr\n",
    "\n",
    "#     print(h_ave[scat_degree].shape)\n",
    "    transverse_intensities_nc.append(h_ave_nc[s][:, h_ave_nc[s].shape[1]//2])\n",
    "    axial_intensities_nc.append(h_ave_nc[s][h_ave_nc[s].shape[1]//2, :])\n",
    "    axial_intensities_std_nc.append(h_ave_nc[s][h_ave_nc[s].shape[1]//2, :])\n",
    "    axial_edges_nc.append(ax_edges)\n",
    "    transverse_edges_nc.append(trans_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_edges_nc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Z = np.meshgrid(axial_edges_nc[0], transverse_edges_nc[0])\n",
    "plots2(X, Z, h_ave_nc[0], alpha=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (transverse_edges[0][1:] + transverse_edges[0][:-1] ) / 2\n",
    "z = (axial_edges[0][1:] + axial_edges[0][:-1] ) / 2\n",
    "X, Z = np.meshgrid(x, z)\n",
    "for s in range(len(step_param_arr)):\n",
    "    plots2(X, Z, h_ave[s], alpha=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam.z_R, beam.w0, beam.f, beam.wavelength, beam.aperture, beam.focal_tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, V = np.meshgrid(u, v)\n",
    "X, Z = beam.change_coords_reverse(V, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots2(U, V, intensity, alpha=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.figure()\n",
    "x = (transverse_edges[0][1:] + transverse_edges[0][:-1] ) / 2\n",
    "z = (axial_edges[0][1:] + axial_edges[0][:-1] ) / 2\n",
    "\n",
    "axint_theo = beam.axial_intensity(z)\n",
    "axint_theo /= np.amax(axint_theo)\n",
    "axint_theo[axint_theo==0] = 1\n",
    "\n",
    "\n",
    "znc = (axial_edges_nc[0][1:] + axial_edges_nc[0][:-1] ) / 2\n",
    "print(znc.shape)\n",
    "axint_theonc = beam.axial_intensity(znc)\n",
    "axint_theonc /= np.amax(axint_theonc)\n",
    "axint_theonc[axint_theonc==0] = 1\n",
    "\n",
    "\n",
    "ztrunc1 = np.abs(z) <= 15 \n",
    "ztrunc2 = np.abs(znc) <= 15\n",
    "\n",
    "xt, zt = beam.change_coords_reverse(v, u)\n",
    "\n",
    "\n",
    "for s in range(len(R)):\n",
    "    pl.figure()\n",
    "    \n",
    "    ax_int_normed = axial_intensities[s] / np.amax(axial_intensities[s])\n",
    "    ax_std_normed = axial_intensities_std[s] / np.amax(axial_intensities_std[s])\n",
    "#     print(f'cross correlation: {cross_correlate_1d(ax_int_normed, axint_theo)}')\n",
    "    C, F, Q = linfoot(ax_int_normed[ztrunc1], axint_theo[ztrunc1])\n",
    "    pl.plot(z[ztrunc1], ax_int_normed[ztrunc1], label=f'SMC: C = {C:.2f}, F = {F:.2f}, Q = {Q:.2f}')\n",
    "    # pl.fill_between(x, ax_int_normed-ax_std_normed, ax_int_normed+ax_std_normed, alpha=0.4)\n",
    "    \n",
    "    \n",
    "    ax_int_normed_nc = axial_intensities_nc[0] / np.amax(axial_intensities_nc[0])\n",
    "    C, F, Q = linfoot(ax_int_normed_nc[ztrunc2], axint_theonc[ztrunc2])\n",
    "    pl.plot(znc[ztrunc2], ax_int_normed_nc[ztrunc2], label=f'CMC: C = {C:.2f}, F = {F:.2f}, Q = {Q:.2f}')\n",
    "    \n",
    "    pl.plot(z, axint_theo/np.amax(axint_theo), label=f'SDT - Tanaka et al.')\n",
    "    pl.plot(zt, axial_profile, label=f'SDT - Horvath & Bor')\n",
    "    pl.xlim(-15, 15)\n",
    "    pl.xlabel(r'$z$ ($\\mu$m)')\n",
    "    pl.ylabel('Normalized intensity')\n",
    "    pl.title(f'$\\epsilon$ = {step_param_arr[s]:.2E}')\n",
    "    pl.axvline(x=-0.5, color='gray')\n",
    "    pl.axvline(x=0.5, color='gray')\n",
    "    \n",
    "    print()\n",
    "    print(f's = {step_param_arr[s]:.2E}')\n",
    "    print(f'Rayleigh length MC: {z[np.argmin(np.abs(ax_int_normed-0.5))]}')\n",
    "    print(f'Rayleigh length SDT2: {zt[np.argmin(np.abs(axial_profile-0.5))]}')\n",
    "    print(f'Rayleigh length SDT: {z[np.argmin(np.abs(axint_theo/np.amax(axint_theo)-0.5))]}')\n",
    "    print(f'{C}, {F}, {Q}')\n",
    "    # pl.ylim(0, 1)\n",
    "    lgd = pl.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#     pl.gca().add_artist(legend1)\n",
    "\n",
    "    arrow = -10.8, 0.958, 3, 0\n",
    "    pl.arrow(*arrow, shape='full', lw=0.5, length_includes_head=False, head_length=0.3, head_width=0.03, color='k')\n",
    "    pl.text(-14.5, 0.95, 'beam propagation \\ndirection')\n",
    "    \n",
    "    pl.savefig(f'axialint-{s}.png', dpi=300, bbox_extra_artists=(lgd,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.figure()\n",
    "x = (transverse_edges[0][1:] + transverse_edges[0][:-1] ) / 2\n",
    "z = (axial_edges[0][1:] + axial_edges[0][:-1] ) / 2\n",
    "vt, ut = beam.change_coords(x, z)\n",
    "trint_theo = beam.transverse_intensity(x, 0)\n",
    "x2 = np.linspace(x[0], x[-1], 100)\n",
    "x3, z3 = beam.change_coords_reverse(v, u)\n",
    "\n",
    "for s in range(len(R)):\n",
    "    pl.figure()\n",
    "#     C, F, Q = linfoot(axial_intensities[s], axint_theo)\n",
    "    tr_int_normed = transverse_intensities[s] / np.amax(transverse_intensities[s])\n",
    "#     print(f'cross correlation: {cross_correlate_1d(ax_int_normed, axint_theo)}')\n",
    "    pl.plot(x, tr_int_normed, label=f'MC')\n",
    "#     pl.plot(x, trint_theo/np.amax(trint_theo), label=f'SDT')\n",
    "    pl.plot(x3, transverse_profile, label=f'SDT - Horvath & Bor')\n",
    "    pl.xlim(-2, 2)\n",
    "    pl.xlabel(r'$x$ ($\\mu$m)')\n",
    "    pl.ylabel('Normalized intensity')\n",
    "    pl.title(f's = {step_param_arr[s]:.2E}')\n",
    "    \n",
    "    # pl.ylim(0, 1)\n",
    "    pl.legend(loc='best')\n",
    "    pl.savefig(f'transverseint-{s}.png', dpi=300)\n",
    "    \n",
    "    print(f'Beam waist MC: {x[np.argmin(np.abs(tr_int_normed - (1/np.e**2)))] - np.mean(x)}')\n",
    "    print(f'Beam waist SDT: {x3[np.argmin(np.abs(transverse_profile - (1/np.e**2)))] - np.mean(x3)}')\n",
    "#     print(f'Beam waist SDT: {x[np.argmin(np.abs(trint_theo/np.amax(trint_theo) - (1/np.e**2)))]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(x3, np.abs(transverse_profile - (1/np.e**2)))\n",
    "pl.plot(x, np.abs(tr_int_normed - (1/np.e**2)))\n",
    "pl.xlim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = []\n",
    "F_list = []\n",
    "Q_list = []\n",
    "for s in range(len(R)):\n",
    "#     pl.figure()\n",
    "    I = h_ave[s].T / np.amax(h_ave[s])\n",
    "    X, Z = np.meshgrid(transverse_edges[scat_degree][:-1], axial_edges[scat_degree][:-1])\n",
    "    cropped = (X < 15) & (Z< 15)\n",
    "    crop_x, crop_z = np.where(cropped == 1)\n",
    "    print(crop_x, crop_z)\n",
    "    \n",
    "#     pl.contour(X, Z, I, levels=np.logspace(-6, 0, 8), cmap=pl.cm.gray, origin='lower', linewidths=0.5)\n",
    "#     pl.title(f'R = {(scat_degree) * 2}')\n",
    "#     pl.xlabel(r'$z$ ($\\mu$m)')\n",
    "#     pl.ylabel(r'$x$ ($\\mu$m)')\n",
    "    C, F, Q = linfoot(I, intensity[:, intensity.shape[1]//2])\n",
    "    print(C, F, Q)\n",
    "    print(2*Q - (C + F))\n",
    "    C_list.append(C)\n",
    "    F_list.append(F)\n",
    "    Q_list.append(Q)\n",
    "\n",
    "        \n",
    "#     pl.savefig(f'intensitydist-R{scat_degree * 2}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.semilogx(step_param_arr, C_list, '.')\n",
    "pl.figure()\n",
    "pl.semilogx(step_param_arr, F_list, '.')\n",
    "pl.figure()\n",
    "pl.semilogx(step_param_arr, Q_list, '.')\n",
    "\n",
    "step_param_arr[np.argmax(np.array(C_list)[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_free_path = []\n",
    "path_length = []\n",
    "\n",
    "for scat_degree in range(len(R)): \n",
    "    free_paths = FREE_PATHS[scat_degree]\n",
    "    start_step = START_STEP[scat_degree]\n",
    "    stop_step = STOP_STEP[scat_degree]\n",
    "    mean_free_path.append([])\n",
    "    path_length.append([])\n",
    "    \n",
    "    for trial in range(5):\n",
    "        paths_in_medium = []\n",
    "        ballistic = 0\n",
    "        for photon in range(free_paths.shape[1]):\n",
    "            start = start_step[trial, photon]\n",
    "            stop = stop_step[trial, photon]\n",
    "            if start==stop:\n",
    "                ballistic += 1\n",
    "            paths_in_medium.extend(free_paths[trial, photon, start:stop-2])\n",
    "        mean_free_path[scat_degree].append(np.average(np.array(paths_in_medium)))\n",
    "        path_length[scat_degree].append(np.sum(np.array(paths_in_medium)))\n",
    "        print(f'number of ballistic photons: {ballistic}')\n",
    "\n",
    "mean_free_path = np.array(mean_free_path)\n",
    "path_length = np.array(path_length)\n",
    "print()\n",
    "print(mean_free_path)\n",
    "print()\n",
    "print(path_length)\n",
    "\n",
    "#     print(f'R={scat_degree*2} \\n Mean free path: {average_mfp} \\n Average number of times scattered: {average_num_times_scattered} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_param_arr[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pl.subplot()\n",
    "# ax.set_xscale(\"log\", nonposx='clip')\n",
    "# ax.set_yscale(\"log\", nonposy='clip')\n",
    "x = 1 / np.arange(2, 5, 2)\n",
    "y = np.average(mean_free_path, axis=1)\n",
    "yerr = np.std(mean_free_path, axis=1)\n",
    "pl.errorbar(x, y, yerr=yerr, fmt='o')\n",
    "# pl.plot(x, y, 'o')\n",
    "pl.xlabel(r'mean free path from Degree of scattering ($d_s = h / R$)')\n",
    "pl.ylabel('Calculated path ($d_s\\'$)')\n",
    "# pl.title('Calculated degree of scattering')\n",
    "## do for higher degrees of scattering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_free_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(np.arange(2,9,2), np.average(mean_free_path[1:], axis=1), 'o')\n",
    "pl.xlabel(r'Degree of scattering $R = h/d_s$')\n",
    "pl.ylabel(r'Mean free path ($\\mu s$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbpmc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "24321795f452392527056cab88b1f4d0745da07a8524a559433ac677793cf663"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
